{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n",
    "\n",
    "Submission File\n",
    "For each id in the test set, you must predict a probability for the target variable. The file should contain a header and have the following format:\n",
    "\n",
    "https://www.kaggle.com/c/tabular-playground-series-nov-2021/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : kaggle-pgnov21\n",
      "    active env location : C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\n",
      "            shell level : 2\n",
      "       user config file : C:\\Users\\globetrekker\\.condarc\n",
      " populated config files : C:\\Users\\globetrekker\\.condarc\n",
      "          conda version : 4.10.3\n",
      "    conda-build version : 3.21.4\n",
      "         python version : 3.8.8.final.0\n",
      "       virtual packages : __win=0=0\n",
      "                          __archspec=1=x86_64\n",
      "       base environment : C:\\ProgramData\\Anaconda3  (writable)\n",
      "      conda av data dir : C:\\ProgramData\\Anaconda3\\etc\\conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/win-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/win-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "                          https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "                          https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "          package cache : C:\\ProgramData\\Anaconda3\\pkgs\n",
      "                          C:\\Users\\globetrekker\\.conda\\pkgs\n",
      "                          C:\\Users\\globetrekker\\AppData\\Local\\conda\\conda\\pkgs\n",
      "       envs directories : C:\\ProgramData\\Anaconda3\\envs\n",
      "                          C:\\Users\\globetrekker\\.conda\\envs\n",
      "                          C:\\Users\\globetrekker\\AppData\\Local\\conda\\conda\\envs\n",
      "               platform : win-64\n",
      "             user-agent : conda/4.10.3 requests/2.25.1 CPython/3.8.8 Windows/10 Windows/10.0.19041\n",
      "          administrator : False\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "c04be2df-43b3-4c66-ae0e-c17ff6bf7a45",
    "_uuid": "e1abf160-08a9-4188-a996-16dcee5395ec",
    "execution": {
     "iopub.execute_input": "2021-11-12T19:01:01.273778Z",
     "iopub.status.busy": "2021-11-12T19:01:01.272805Z",
     "iopub.status.idle": "2021-11-12T19:01:01.309507Z",
     "shell.execute_reply": "2021-11-12T19:01:01.308884Z",
     "shell.execute_reply.started": "2021-11-12T19:01:01.273661Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "# Table of contents \n",
    "* [Imports](#imports)\n",
    "* [Useful functions](#useful-functions)\n",
    "* [Plot distributions](#plot-distributions)\n",
    "* [Get baseline scores](#get-baseline)\n",
    "* [Optimize models](#optimize-models)\n",
    "* [Drop features](#drop-features)\n",
    "* [Feature importances](#feature-importances)\n",
    "* [KMeans clustering](#kmeans)\n",
    "* [Stacking - manual](#stacking-manual)\n",
    "* [Stacking - auto](#stacking-auto)\n",
    "* [Optuna](#optuna)\n",
    "* [Final](#final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a>\n",
    "## Imports\n",
    "[Go back to top](#imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T19:01:01.311465Z",
     "iopub.status.busy": "2021-11-12T19:01:01.311078Z",
     "iopub.status.idle": "2021-11-12T19:01:03.981131Z",
     "shell.execute_reply": "2021-11-12T19:01:03.980277Z",
     "shell.execute_reply.started": "2021-11-12T19:01:01.311436Z"
    }
   },
   "outputs": [],
   "source": [
    "import time, gc, copy\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "%config Completer.use_jedi = False\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T19:01:03.982595Z",
     "iopub.status.busy": "2021-11-12T19:01:03.982360Z",
     "iopub.status.idle": "2021-11-12T19:01:36.399994Z",
     "shell.execute_reply": "2021-11-12T19:01:36.399324Z",
     "shell.execute_reply.started": "2021-11-12T19:01:03.982567Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_datasets(path: str, scale: bool, debug: bool):\n",
    "    \"\"\"Import datasets from path. Expect csvs called train.csv and test.csv\n",
    "\n",
    "    Arguments:\n",
    "    :path - path containing csvs\n",
    "    :scale - run standard scaler\n",
    "    :debug - run in debug mode\n",
    "    \n",
    "    Returns:\n",
    "    :X - dataframe (train) minus target\n",
    "    :y - series (target values for train)\n",
    "    :df_test - dataframe (test) \n",
    "    \"\"\"\n",
    "    \n",
    "    if debug:\n",
    "        df_train = pd.read_csv(path + 'train.csv', nrows=1000)\n",
    "        df_test = pd.read_csv(path + 'test.csv', nrows=1000)\n",
    "    else:\n",
    "        df_train = pd.read_csv(path + 'train.csv')\n",
    "        df_test = pd.read_csv(path + 'test.csv')\n",
    "        \n",
    "    ids = df_test.id\n",
    "    df_train.drop('id', axis=1, inplace=True)\n",
    "    df_test.drop('id', axis=1, inplace=True)\n",
    "\n",
    "    original_features = df_test.columns\n",
    "\n",
    "    X = df_train[original_features]\n",
    "    y = df_train['target']\n",
    "    \n",
    "    if scale:\n",
    "        std_scaler = StandardScaler()\n",
    "        X_norm = pd.DataFrame(std_scaler.fit_transform(X))\n",
    "        X_norm.columns = original_features\n",
    "        df_test_norm = pd.DataFrame(std_scaler.transform(df_test))\n",
    "        df_test_norm.columns = original_features\n",
    "    else:\n",
    "        X_norm = X\n",
    "        df_test_norm = df_test\n",
    "    \n",
    "    return X_norm, y, df_test_norm, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    \"\"\"Return list of models for initial analysis\n",
    "    \n",
    "    Returns:\n",
    "    :models - list of dicts(name, model)\n",
    "    \"\"\"\n",
    "    models = [\n",
    "        {'name': 'lr', 'model': LogisticRegression(random_state=5)},\n",
    "        {'name': 'lsvc', 'model': LinearSVC(dual=False, random_state=5)},\n",
    "        {'name': 'lgbm', 'model': LGBMClassifier(random_state=5)},\n",
    "        {'name': 'bayes', 'model': GaussianNB()},\n",
    "    ]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model, \n",
    "    X: pd.DataFrame, \n",
    "    y: pd.Series) -> list:\n",
    "    \"\"\"Return list of scores for a model\n",
    "\n",
    "    Arguments:\n",
    "    :model - model to be evaluated\n",
    "    :X - dataframe (train) minus target\n",
    "    :y - series (target values for train)\n",
    "    \n",
    "    Returns:\n",
    "    scores - list of scores for model\n",
    "    \"\"\"\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_val_set(\n",
    "    model, \n",
    "    X_train: pd.DataFrame, \n",
    "    y_train: pd.Series,\n",
    "    X_val: pd.DataFrame,\n",
    "    y_val: pd.Series) -> float:\n",
    "    \"\"\"Return scores for a model on validation set\n",
    "\n",
    "    Arguments:\n",
    "    :model - model to be evaluated\n",
    "    :X_train - training dataframe minus target\n",
    "    :y_train - training series (target values for training set)\n",
    "    :X_val - validation dataframe minus target\n",
    "    :y_val - validation series (target values for validation set)\n",
    "    \n",
    "    Returns:\n",
    "    score - score for model\n",
    "    \"\"\"\n",
    "    if model.__class__.__name__ == 'LinearSVC':\n",
    "        clf = CalibratedClassifierCV(base_estimator=model, cv=5)\n",
    "    else:\n",
    "        clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    score = roc_auc_score(y_val, preds)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(\n",
    "    X_in: pd.DataFrame, \n",
    "    y_in: pd.Series, \n",
    "    model_type: str, \n",
    "    k: int) -> pd.DataFrame:\n",
    "    \"\"\"Return feature importances of features as to the target prediction\n",
    "\n",
    "    Arguments:\n",
    "    :X_in - dataframe (train) minus target\n",
    "    :y_in - series (target values for train)\n",
    "    :model_type - 'regression' or 'classification'\n",
    "    :k - number of folds \n",
    "    \n",
    "    Returns:\n",
    "    :featureScores - dataframe with abs correlation value sorted in asc\n",
    "    \"\"\"\n",
    "    if model_type == 'classification':\n",
    "        bestfeatures = SelectKBest(score_func=f_classif, k=k)\n",
    "    else:\n",
    "        bestfeatures = SelectKBest(score_func=f_regression, k=k)\n",
    "    \n",
    "    fit = bestfeatures.fit(X_in, y_in)\n",
    "\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X_in.columns)\n",
    "\n",
    "    # Concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score'] \n",
    "    featureScores['Abs_score'] = abs(featureScores['Score'])\n",
    "    featureScores.sort_values(by='Score', axis=0, ascending=True, inplace=True)\n",
    "    featureScores.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return featureScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_labels(\n",
    "    X_in: pd.DataFrame, \n",
    "    features: list,\n",
    "    n_clusters: int) -> list:\n",
    "    \"\"\"Return kmeans labels for a dataframe\n",
    "\n",
    "    Arguments:\n",
    "    :X_in - dataframe (train) minus target\n",
    "    :features - list of important features\n",
    "    :n_clusters - number of kmeans clusters\n",
    "    \n",
    "    Returns:\n",
    "    X_temp - dataframe (train) minus target plus kmeans labels\n",
    "    \"\"\"\n",
    "    X_temp = copy.deepcopy(X_in)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=3)\n",
    "    kmeans.fit(X_temp[features])\n",
    "    X_temp['cluster'] = kmeans.predict(X_temp[features])\n",
    "    \n",
    "    return X_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_dist_ratios(\n",
    "    X_in: pd.DataFrame, \n",
    "    X_val_in: pd.DataFrame,\n",
    "    X_test_in: pd.DataFrame,\n",
    "    features: list,\n",
    "    n_clusters: int) -> list:\n",
    "    \"\"\"Return kmeans labels for a dataframe\n",
    "\n",
    "    Arguments:\n",
    "    :X_in - dataframe (train) minus target\n",
    "    :X_val_in - dataframe (val) minus target\n",
    "    :X_test_in - dataframe (test) minus target\n",
    "    :features - list of important features\n",
    "    :n_clusters - number of kmeans clusters\n",
    "    \n",
    "    Returns:\n",
    "    :X_temp - dataframe (train) minus target plus kmeans dist ratios\n",
    "    :X_temp_val - dataframe (val) minus target plus kmeans dist ratios\n",
    "    :X_temp_test - dataframe (test) minus target plus kmeans dist ratios\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=3)\n",
    "    X_temp = copy.deepcopy(X_in)\n",
    "    X_temp_val = copy.deepcopy(X_val_in)\n",
    "    X_temp_test = copy.deepcopy(X_test_in)\n",
    "    \n",
    "    kmeans.fit(X_temp[features])\n",
    "    cluster_cols = [f\"cluster{i+1}\" for i in range(n_clusters)]\n",
    "\n",
    "    cluster_distances = kmeans.transform(X_temp[features])\n",
    "    cluster_distances_val = kmeans.transform(X_temp_val[features])\n",
    "    cluster_distances_test = kmeans.transform(X_temp_test[features])\n",
    "    \n",
    "    X_temp_cluster_distances = pd.DataFrame(cluster_distances, columns=cluster_cols, index=X_temp.index)\n",
    "    X_temp_val_cluster_distances = pd.DataFrame(cluster_distances_val, columns=cluster_cols, index=X_temp_val.index)\n",
    "    X_temp_test_cluster_distances = pd.DataFrame(cluster_distances_test, columns=cluster_cols, index=X_temp_test.index)\n",
    "\n",
    "    new_cols = []\n",
    "    for i in cluster_cols:\n",
    "        for j in cluster_cols:\n",
    "            if i != j:\n",
    "                new_col_name = i + '_' + j\n",
    "                X_temp_cluster_distances[new_col_name] = X_temp_cluster_distances[i] / X_temp_cluster_distances[j]\n",
    "                X_temp_val_cluster_distances[new_col_name] = X_temp_val_cluster_distances[i] / X_temp_val_cluster_distances[j]\n",
    "                X_temp_test_cluster_distances[new_col_name] = X_temp_test_cluster_distances[i] / X_temp_test_cluster_distances[j]\n",
    "                new_cols.append(new_col_name)\n",
    "            \n",
    "    X_temp = X_temp.join(X_temp_cluster_distances[new_cols])\n",
    "    X_temp_val = X_temp_val.join(X_temp_val_cluster_distances[new_cols])\n",
    "    X_temp_test = X_temp_test.join(X_temp_test_cluster_distances[new_cols])\n",
    "    \n",
    "    return X_temp, X_temp_val, X_temp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_meta_features_model(model, X_in, y_in, cv):\n",
    "    \"\"\"Generate meta features for single base classifier model, to be used later for stacking\n",
    "\n",
    "    Arguments:\n",
    "    :model - model to evaluate\n",
    "    :X_in - dataframe with features minus target\n",
    "    :y_in - target series\n",
    "    :cv - cross-validation iterator \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize\n",
    "    n_classes = len(np.unique(y_in)) # Assuming that training data contains all classes\n",
    "    meta_features = np.zeros((X_in.shape[0], n_classes)) \n",
    "    n_splits = cv.get_n_splits(X_in, y_in)\n",
    "    \n",
    "    # Loop over folds\n",
    "    print(\"Starting hold out prediction with {} splits for {}.\".format(n_splits, model.__class__.__name__))\n",
    "    for train_idx, hold_out_idx in cv.split(X_in, y_in): \n",
    "        \n",
    "        # Split data\n",
    "        X_in_train = X_in.iloc[train_idx]    \n",
    "        y_in_train = y_in.iloc[train_idx]\n",
    "        X_in_hold_out = X_in.iloc[hold_out_idx]\n",
    "\n",
    "        # Fit estimator to K-1 parts and predict on hold out part\n",
    "        est = copy.deepcopy(model)\n",
    "        est.fit(X_in_train, y_in_train)\n",
    "        y_in_hold_out_pred = est.predict_proba(X_in_hold_out)\n",
    "        \n",
    "        # Fill in meta features\n",
    "        meta_features[hold_out_idx] = y_in_hold_out_pred\n",
    "\n",
    "    return meta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stack_df(models, X_input, X_input_km, y_in):\n",
    "    # Loop over classifier to produce meta features\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=5)\n",
    "    meta_train = []\n",
    "    meta_test = []\n",
    "    for model in models:\n",
    "        name = model['name']\n",
    "        if name == 'lr':\n",
    "            X_in = X_input\n",
    "        elif name == 'lsvc':\n",
    "            X_in = X_input\n",
    "        else:\n",
    "            X_in = X_input_km\n",
    "        \n",
    "        # Create hold out predictions for a classifier\n",
    "        if model['model'].__class__.__name__ == 'LinearSVC':\n",
    "            clf = CalibratedClassifierCV(base_estimator=model['model'], cv=5)\n",
    "        else:\n",
    "            clf = model['model']\n",
    "        meta_train_model = generate_meta_features_model(clf, X_in, y_in, cv)\n",
    "\n",
    "        # Remove redundant column - 0th column = 1-first column in a two class dataset \n",
    "        meta_train_model = np.delete(meta_train_model, 0, axis=1).ravel()\n",
    "        print(pd.DataFrame(meta_train_model).head())\n",
    "\n",
    "        # Gather meta training data\n",
    "        meta_train.append(meta_train_model)\n",
    "\n",
    "    meta_train = np.array(meta_train).T \n",
    "    df_meta_train = pd.DataFrame(meta_train)\n",
    "\n",
    "    # Optional (Add original features to meta)\n",
    "    df_meta_train = pd.DataFrame(np.concatenate((df_meta_train, X_in), axis=1))\n",
    "    \n",
    "    return df_meta_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stack_df_val(models, stack_model, X_input, X_input_km, y_in, X_test_input, X_test_km_input, features, ids):\n",
    "    \n",
    "    meta_test = []\n",
    "    for model in models:\n",
    "        name = model['name']\n",
    "    if name == 'lr':\n",
    "        X_in = X_input\n",
    "        X_test_in = X_test_input\n",
    "    elif name == 'lsvc':\n",
    "        X_in = X_input\n",
    "        X_test_in = X_test_input\n",
    "    else:\n",
    "        X_in = X_input_km\n",
    "        X_test_in = X_test_km_input\n",
    "\n",
    "    clf.fit(X_in, y_in)\n",
    "    meta_test_model = clf.predict_proba(X_test_in)\n",
    "\n",
    "    # Remove redundant column - 0th column = 1-first column in a two class dataset \n",
    "    meta_test_model = np.delete(meta_test_model, 0, axis=1).ravel()\n",
    "\n",
    "    # Gather meta training data\n",
    "    meta_test.append(meta_test_model)\n",
    "\n",
    "    meta_test = np.array(meta_test).T \n",
    "    df_meta_test = pd.DataFrame(meta_test)\n",
    "\n",
    "    # Optional (Add original features to meta)\n",
    "    df_meta_test = pd.DataFrame(np.concatenate((df_meta_test, X_test_in), axis=1))\n",
    "    \n",
    "    return df_meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_logreg(trial, X_in, y_in, X_val_in, y_val_in):\n",
    "    \"\"\"Optimize logistic regression model using optuna\"\"\"\n",
    "    \n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'newton-cg', 'lbfgs', 'newton-cg', 'sag', 'saga'])\n",
    "    C = trial.suggest_float(\"C\", 0.01, 2.0)\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100, 10000, step=100)\n",
    "    \n",
    "    penalty = 'l2'\n",
    "    \n",
    "    model = LogisticRegression(C=C, max_iter=max_iter, solver=solver, penalty=penalty)\n",
    "    model.fit(X_in, y_in)\n",
    "    preds = model.predict_proba(X_val_in)[:,1]\n",
    "    score = roc_auc_score(y_val_in, preds)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_linearSVC(trial, X_in, y_in, X_val_in, y_val_in):\n",
    "    \"\"\"Optimize linear SVC model using optuna\"\"\"\n",
    "    \n",
    "    C = trial.suggest_float(\"C\", 0.01, 2.0)\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 1000, 10000, step=1000)\n",
    "    \n",
    "    model = LinearSVC(C=C\n",
    "                      , max_iter=max_iter\n",
    "                      , dual=False\n",
    "                      , random_state=5)\n",
    "    clf = CalibratedClassifierCV(base_estimator=model, cv=5)\n",
    "    clf.fit(X_in, y_in)\n",
    "    \n",
    "    preds = clf.predict_proba(X_val_in)[:,1]\n",
    "    score = roc_auc_score(y_val_in, preds)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "X, y, df_test, ids = get_datasets('../input/tabular-playground-series-nov-2021/', True, False)\n",
    "original_features = list(df_test.columns)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, train_size=0.8)\n",
    "\n",
    "# get models\n",
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.749 (0.002)\n",
      ">lsvc 0.749 (0.002)\n",
      ">lgbm 0.732 (0.002)\n",
      ">bayes 0.636 (0.003)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate baseline cross val scores of the models\n",
    "results, names = list(), list()\n",
    "for model in models:\n",
    "    name = model['name']\n",
    "    scores = evaluate_model(model['model'], X_train, y_train)\n",
    "    model['init_scores'] = np.mean(scores)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.title('Baseline Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get feature importances\n",
    "featureScores = get_feature_importances(X_train, y_train, 'classification', 5)\n",
    "plt.bar(featureScores['Specs'], featureScores['Abs_score'])\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lgbm 0.737 (0.002)\n",
      ">bayes 0.710 (0.002)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate cross val scores for the models by adding kmeans cluster distance ratios\n",
    "results, names = list(), list()\n",
    "important_features = list(featureScores.sort_values(by='Abs_score', ascending=False).head(15)['Specs'])\n",
    "X_train_km, X_val_km, X_test_km = get_kmeans_dist_ratios(X_train, X_val, df_test, important_features, 10)\n",
    "for model in models:\n",
    "    name = model['name']\n",
    "    if name == 'lr':\n",
    "        pass\n",
    "    elif name == 'lsvc':\n",
    "        pass\n",
    "    else:\n",
    "        scores = evaluate_model(model['model'], X_train_km, y_train)\n",
    "        model['kmeans_dist_rat_scores'] = np.mean(scores)\n",
    "        results.append(scores)\n",
    "        names.append(name)\n",
    "        print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.title('KMeans Distance Ratio Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.748\n",
      ">lsvc 0.748\n",
      ">lgbm 0.731\n",
      ">bayes 0.633\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline scores of the models on validation set\n",
    "for model in models:\n",
    "    name = model['name']\n",
    "    score = evaluate_model_val_set(model['model'], X_train, y_train, X_val, y_val)\n",
    "    model['init_scores_val'] = score\n",
    "    print('>%s %.3f' % (name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lgbm 0.735\n",
      ">bayes 0.710\n"
     ]
    }
   ],
   "source": [
    "# evaluate score on val set with kmeans dist ratios added\n",
    "important_features = list(featureScores.sort_values(by='Abs_score', ascending=False).head(15)['Specs'])\n",
    "X_train_km, X_val_km, X_test_km = get_kmeans_dist_ratios(X_train, X_val, df_test, important_features, 10)\n",
    "for model in models:\n",
    "    name = model['name']\n",
    "    if name == 'lr':\n",
    "        pass\n",
    "    elif name == 'lsvc':\n",
    "        pass\n",
    "    else:\n",
    "        score = evaluate_model_val_set(model['model'], X_train_km, y_train, X_val_km, y_val)\n",
    "        model['kmeans_dist_rat_scores_val'] = score\n",
    "        print('>%s %.3f' % (name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 100 iterations\n",
      "Starting hold out prediction with 5 splits for LogisticRegression.\n",
      "          0\n",
      "0  0.229223\n",
      "1  0.695775\n",
      "2  0.568647\n",
      "3  0.722557\n",
      "4  0.645760\n",
      "Starting hold out prediction with 5 splits for CalibratedClassifierCV.\n",
      "          0\n",
      "0  0.231152\n",
      "1  0.695096\n",
      "2  0.567928\n",
      "3  0.722188\n",
      "4  0.643830\n",
      "Starting hold out prediction with 5 splits for GaussianNB.\n",
      "              0\n",
      "0  5.501525e-10\n",
      "1  9.953064e-01\n",
      "2  3.057126e-02\n",
      "3  9.999980e-01\n",
      "4  1.000000e+00\n",
      ">['lr_', 'lsvc_', 'bayes_'] 0.746 (0.002)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate scores with stacking\n",
    "# get km enhanced df\n",
    "important_features = list(featureScores.sort_values(by='Abs_score', ascending=False).head(15)['Specs'])\n",
    "X_train_km, X_val_km, X_test_km = get_kmeans_dist_ratios(X_train, X_val, df_test, important_features, 10)\n",
    "stack_model = LogisticRegression(solver='sag', C=1.6213309780417264, max_iter=1800, random_state=10)\n",
    "\n",
    "# get meta df\n",
    "models_stack = copy.deepcopy(models)\n",
    "models_stack.pop(2)\n",
    "df_meta_train = get_stack_df(models_stack, X_train, X_train_km, y_train)\n",
    "\n",
    "# cross val scores from stacking\n",
    "results = list()\n",
    "name = [model['name'] +'_' for model in models_stack]\n",
    "scores = evaluate_model(stack_model, df_meta_train, y_train)\n",
    "score = np.mean(scores)\n",
    "results.append(scores)\n",
    "print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "\n",
    "# plot stack model performance for comparison\n",
    "plt.boxplot(results, labels=['stack - ' + stack_model.__class__.__name__], showmeans=True)\n",
    "plt.title('Stacking Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 100 iterations\n",
      "Starting hold out prediction with 5 splits for LogisticRegression.\n",
      "          0\n",
      "0  0.229223\n",
      "1  0.695775\n",
      "2  0.568647\n",
      "3  0.722557\n",
      "4  0.645760\n",
      "Starting hold out prediction with 5 splits for CalibratedClassifierCV.\n",
      "          0\n",
      "0  0.231152\n",
      "1  0.695096\n",
      "2  0.567928\n",
      "3  0.722188\n",
      "4  0.643830\n",
      "Starting hold out prediction with 5 splits for LGBMClassifier.\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "          0\n",
      "0  0.260928\n",
      "1  0.698825\n",
      "2  0.456899\n",
      "3  0.741388\n",
      "4  0.609898\n",
      ">['lr_', 'lsvc_', 'lgbm_'] 0.747 (0.002)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stack_model = LogisticRegression(solver='sag', C=1.6213309780417264, max_iter=1800, random_state=10)\n",
    "\n",
    "# get meta df\n",
    "models_stack = copy.deepcopy(models)\n",
    "models_stack.pop(3)\n",
    "df_meta_train = get_stack_df(models_stack, X_train, X_train_km, y_train)\n",
    "\n",
    "# cross val scores from stacking\n",
    "results = list()\n",
    "name = [model['name'] +'_' for model in models_stack]\n",
    "scores = evaluate_model(stack_model, df_meta_train, y_train)\n",
    "score = np.mean(scores)\n",
    "results.append(scores)\n",
    "print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "\n",
    "# plot stack model performance for comparison\n",
    "plt.boxplot(results, labels=['stack - ' + stack_model.__class__.__name__], showmeans=True)\n",
    "plt.title('Stacking Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 100 iterations\n",
      "Starting hold out prediction with 5 splits for LogisticRegression.\n",
      "          0\n",
      "0  0.229223\n",
      "1  0.695775\n",
      "2  0.568647\n",
      "3  0.722557\n",
      "4  0.645760\n",
      "Starting hold out prediction with 5 splits for LGBMClassifier.\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "          0\n",
      "0  0.260928\n",
      "1  0.698825\n",
      "2  0.456899\n",
      "3  0.741388\n",
      "4  0.609898\n",
      "Starting hold out prediction with 5 splits for GaussianNB.\n",
      "              0\n",
      "0  5.501525e-10\n",
      "1  9.953064e-01\n",
      "2  3.057126e-02\n",
      "3  9.999980e-01\n",
      "4  1.000000e+00\n",
      ">['lr_', 'lgbm_', 'bayes_'] 0.746 (0.002)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcPklEQVR4nO3de5hfVWHu8e/rAIZLuElAIKFQD2gwcnJwxFpoMVgxCIHSi5IDj3CM5gmViFZAOHNq1UqrjVUUaWMKHDmCgzcwCAjhYMQGxWbCNTFcUg6aEDTB4A0M5PKeP/Ya+sswk9mTmWQy2e/neeaZ2WutvffaP8h+f3vtm2wTERHN87Lh7kBERAyPBEBEREMlACIiGioBEBHRUAmAiIiGSgBERDRUAiAaSdKXJH2ij7rZkv5mW/cpYltLAMR2RdJxkn4g6VeS1ki6W9IbSt05khZs7T7YnmH777bGsiVNk/SwpN9I+rmkWySN3hrriujPTsPdgYhukvYEbgbOBb4G7AL8EfD8cPZrqEg6Hvh7YLLt+yTtC0wZ4nXsZHv9UC4zdlw5AojtyREAtjttb7D9O9vzbD8oaTwwG3iTpN9K+iWApJMl3Sfp15KWS/po6wJbjih+WerP6blSSaMlzZf0eVVeHB6S9GZJKyR9SNIqSU9J+h8t875C0rfL+hdK+sRmjlLeAPzQ9n1lO9fYvsb2b8qydpX0T5J+Uo6AFkjatdSdKmlJ2Y7vlc+juw9PSPqwpAeBZyXtJOkPWrb7AUlvbml/jqTHy1HI/5N05sD+M8WOIgEQ25NHgQ2SrpF0kqR9uitsLwVmUO1A97C9d6l6FngXsDdwMnCupD8FkHQI8B3gcmAMMBG4v3WFkl4B3Ancbfv97v3ZKK8E9gIOBqYBV7T07YrSh1cCZ5efvvwIeJukj0k6VtLLe9R/Gng98IfAvsBFwEZJRwCdwAfKdtwKfFvSLi3zTi3bvzdwAHAL8ImynAuAb0oaI2l34PPASbZHl3Vt8plEcyQAYrth+9fAcYCBfwVWS7pJ0gGbmed7th+yvdH2g1Q7yuNL9ZnA/y1HFOts/8L2/S2zHwTcBXzd9v/aTNfWAR8vy7gV+C3wakltwJ8Df2v7Ods/Bq7ZTF//Dfgz4GiqHfQvJH1GUpuklwHvBs63/WQ5AvqB7eeBdwK32L7D9jqqoNiVaufd7fO2l9v+HXAWcKvtW8vncgfQBby9tN0ITJC0q+2nbC/ZzLbHDiwBENsV20ttn2N7LDCBaid9WV/tJb2xDN+slvQrqqOE/Ur1OOA/NrO6k6l2pLP76dYveoyrPwfsQfVtfCdgeUtd698vYfs7tqdQfTM/DTgHeE/p86g++nsQ8JOWZWws6zm4j/X+HvCXZfjnl2W47DjgQNvPUgXKDOCpchL6NZvrc+y4EgCx3bL9MPAlqiCA6sigp68ANwHjbO9FtTNXqVsOvGozq/hX4Dbg1jI0MlCrgfXA2JaycXVmLN/M7wS+S7V9TwNr++jvSqqdOgCSVNbzZOsiW/5eDnzZ9t4tP7vb/mRZ9+223wocCDxM9TlEAyUAYrsh6TXlZOvYMj2Oamz7ntLk58DYHmPfo4E1ttdKOgb47y111wF/Iukd5cToKyRN7LHa84BHgJu7T7jWZXsDcAPwUUm7lW/S79rM9p0m6QxJ+5STzcdQDVfdU77VXw18RtJBZVjoTeU8wdeAkyW9RdLOwIeoroz6QR+ruhaYIultZTmjysnssZIOKCeUdy/L+C2wYSDbHTuOBEBsT34DvBH4kaRnqXb8i6l2eFB9W14C/EzS06Xsr4CPS/oN8BGqnSUAtn9KNe79IWAN1cnO/9q6wnLSdzrVt+a5kkYNsM/nUZ0g/hnwZapzEH1dtvoM8F7gMeDXVDvqWbavK/UXAA8BC0t/PwW8zPYjVOP6l1MdKUwBpth+obeV2F5ONbz0P6mOUpYDF1L9e38Z1eexsqzjeKrPMBpIeSFMxNCR9CnglbY3dzVQxHYhRwARg1CGrY5qGdKZBtw43P2KqCN3AkcMzmiqYZ+DgFXAPwFzh7VHETXVGgKSNBn4HNAGXNl9NUFL/YVU11xDFSrjgTG210h6gmpsdwOw3nZ7j3kvAGaV9k8TERHbRL8BUG52eRR4K7CC6gTV1HLTS2/tpwAftH1CmX4CaO9t516u8rgSeA3w+gRARMS2U2cI6Bhgme3HASRdT3WFQa8BQHXZXmfN9X+W6nb3WofM++23nw899NCai46ICIBFixY9bXtMz/I6AXAwm95luILqUr2XkLQbMJnq0rhuBuZJMvBF23NK21OBJ20/UN3X0jtJ06ku0+OQQw6hq6urRpcjIqKbpJ/0Vl4nAHrbO/c1bjSF6qFaa1rKjrW9UtL+wB2SHqZ6LkkHcGJ/Ky+BMQegvb0916xGRAyROpeBrmDT29vHUt1E0psz6DH8Y3tl+b2K6vK4Y6hudz8MeKCcIxgL3CvplQPpfEREbLk6AbAQOFzSYeUW/DOonr2yCUl7Ud1VOLelbHeVtx2VW89PBBaXpzfub/tQ24dShczRtn826C2KiIha+h0Csr1e0nnA7VSXgV5te4mkGaW++0mKpwPzytMGux0A3FjG+HcCvmL7tqHcgIiI2DIj6lEQ7e3tzkngiIiBkbSo5z1YkEdBRAxKZ2cnEyZMoK2tjQkTJtDZWfcK6Ijhl0dBRGyhzs5OOjo6uOqqqzjuuONYsGAB06ZNA2Dq1KnD3LuI/mUIKGILTZgwgcsvv5xJkya9WDZ//nxmzpzJ4sWLh7FnEZvqawgoARCxhdra2li7di0777zzi2Xr1q1j1KhRbNiQd6zE9iPnACKG2Pjx41mwYMEmZQsWLGD8+PHD1KOIgUkARGyhjo4Opk2bxvz581m3bh3z589n2rRpdHR0DHfXImrJSeCILdR9onfmzJksXbqU8ePHc+mll+YEcIwYOQcQEbGDyzmAiIjYRAIgIqKhEgAREQ2VAIiIaKgEQEREQyUAIiIaKgEQEdFQCYCIiIZKAERENFQCICKioRIAERENlQCIiGioBEBEREMlACIiGioBEBHRUAmAiIiGSgBERDRUAiAioqFqBYCkyZIekbRM0sW91F8o6f7ys1jSBkn7lronJD1U6rpa5pkl6WFJD0q6UdLeQ7ZVERHRr34DQFIbcAVwEnAkMFXSka1tbM+yPdH2ROAS4C7ba1qaTCr1re+kvAOYYPso4NEyX0REbCN1jgCOAZbZftz2C8D1wGmbaT8V6Oxvobbn2V5fJu8BxtboS0REDJE6AXAwsLxlekUpewlJuwGTgW+2FBuYJ2mRpOl9rOPdwHdq9CUiIobITjXaqJcy99F2CnB3j+GfY22vlLQ/cIekh21//8WFSx3AeuC6XldehcZ0gEMOOaRGdyMioo46RwArgHEt02OBlX20PYMewz+2V5bfq4AbqYaUAJB0NnAKcKbtXkPF9hzb7bbbx4wZU6O7ERFRR50AWAgcLukwSbtQ7eRv6tlI0l7A8cDclrLdJY3u/hs4EVhcpicDHwZOtf3cYDckIiIGpt8hINvrJZ0H3A60AVfbXiJpRqmfXZqeDsyz/WzL7AcAN0rqXtdXbN9W6r4AvJxqWAjgHtszhmCbIiKiBvUx8rJdam9vd1dXV/8NIyLiRZIW9bgMH8idwBERjZUAiIhoqARARERDJQAiIhoqARAR0VAJgIiIhkoAREQ0VAIgIqKhEgAREQ2VAIgYhM7OTiZMmEBbWxsTJkygs7PfV2FEbDfqPA46InrR2dlJR0cHV111FccddxwLFixg2rRpAEydOnWYexfRvzwLKGILTZgwgcsvv5xJkya9WDZ//nxmzpzJ4sWLh7FnEZvq61lACYCILdTW1sbatWvZeeedXyxbt24do0aNYsOGDcPYs4hN5WFwEUNs/PjxLFiwYJOyBQsWMH78+GHqUcTAJAAitlBHRwfTpk1j/vz5rFu3jvnz5zNt2jQ6OjqGu2sRteQkcMQW6j7RO3PmTJYuXcr48eO59NJLcwI4RoycA4iI2MHlHEBERGwiARAR0VAJgIiIhkoAREQ0VAIgIqKhEgAREQ2VAIiIaKgEQEREQyUAIiIaKgEQEdFQtQJA0mRJj0haJuniXuovlHR/+VksaYOkfUvdE5IeKnVdLfPsK+kOSY+V3/sM3WZFRER/+g0ASW3AFcBJwJHAVElHtraxPcv2RNsTgUuAu2yvaWkyqdS3PoviYuBO24cDd5bpiIjYRuocARwDLLP9uO0XgOuB0zbTfipQ58WopwHXlL+vAf60xjwRETFE6gTAwcDylukVpewlJO0GTAa+2VJsYJ6kRZKmt5QfYPspgPJ7/z6WOV1Sl6Su1atX1+huRETUUScA1EtZX8+QngLc3WP451jbR1MNIb1P0h8PpIO259hut90+ZsyYgcwaERGbUScAVgDjWqbHAiv7aHsGPYZ/bK8sv1cBN1INKQH8XNKBAOX3qvrdjoiIwaoTAAuBwyUdJmkXqp38TT0bSdoLOB6Y21K2u6TR3X8DJwKLS/VNwNnl77Nb54uIiK2v31dC2l4v6TzgdqANuNr2EkkzSv3s0vR0YJ7tZ1tmPwC4UVL3ur5i+7ZS90nga5KmAT8F/nIoNigiIurJKyEjInZweSVkRERsot8hoIgmKsOWW91IOgKPHU8CIKIXA90xS8rOPEacDAFFRDRUAiAioqESABERDZUAiIhoqARARERDJQAiIhoqARAR0VAJgIiIhkoAREQ0VAIgIqKhEgAREQ2VAIiIaKgEQEREQyUAIiIaKgEQEdFQCYCIiIZKAERENFQCICKioRIAERENlQCIiGioBEBEREMlACIiGioBEBHRULUCQNJkSY9IWibp4l7qL5R0f/lZLGmDpH1b6tsk3Sfp5payiZLuKfN0STpmaDYpIiLq6DcAJLUBVwAnAUcCUyUd2drG9izbE21PBC4B7rK9pqXJ+cDSHov+R+BjZZ6PlOmIiNhG6hwBHAMss/247ReA64HTNtN+KtDZPSFpLHAycGWPdgb2LH/vBays2+mIiBi8nWq0ORhY3jK9Anhjbw0l7QZMBs5rKb4MuAgY3aP5B4DbJX2aKoj+sFaPIyJiSNQ5AlAvZe6j7RTg7u7hH0mnAKtsL+ql7bnAB22PAz4IXNXryqXp5RxB1+rVq2t0NyIi6qgTACuAcS3TY+l7uOYMWoZ/gGOBUyU9QTV0dIKka0vd2cAN5e+vUw01vYTtObbbbbePGTOmRncjIqKOOgGwEDhc0mGSdqHayd/Us5GkvYDjgbndZbYvsT3W9qFlvu/aPqtUryztAU4AHtvirYiIiAHr9xyA7fWSzgNuB9qAq20vkTSj1M8uTU8H5tl+tua63wt8TtJOwFpg+oB7HxERW0x2X8P525/29nZ3dXUNdzciXkISI+nfUjSLpEW223uW507giIiGSgBERDRUAiAioqESABERDZUAiIhoqARARERDJQAiIhoqARAR0VAJgIiIhkoAREQ0VAIgIqKhEgAREQ2VAIiIaKgEQEREQyUAIiIaKgEQEdFQ/b4RLGKk23fffXnmmWe2+nokbdXl77PPPqxZs2arriOaJQEQO7xnnnlmh3hb19YOmGieDAFFRDRUAiAioqESABGDtPq51Zxz2zk8/bunh7srEQOSAIgYpNkPzuben9/L7AdmD3dXIgYkARAxCKufW83cZXMx5lvLvpWjgBhREgARgzD7wdls9EYANnpjjgJiREkARGyh7m//6zauA2DdxnU5CogRJQEQsYVav/13y1FAjCQJgIgt9MCqB1789t9t3cZ13L/q/uHpUMQA1boTWNJk4HNAG3Cl7U/2qL8QOLNlmeOBMbbXlPo2oAt40vYpLfPNBM4D1gO32L5ocJsTse1849RvDHcXIgal3wAoO+8rgLcCK4CFkm6y/ePuNrZnAbNK+ynAB7t3/sX5wFJgz5blTgJOA46y/byk/YdgeyIioqY6Q0DHAMtsP277BeB6qh13X6YCnd0TksYCJwNX9mh3LvBJ288D2F41kI5HRMTg1BkCOhhY3jK9Anhjbw0l7QZMphrW6XYZcBEwukfzI4A/knQpsBa4wPbCXpY5HZgOcMghh9TobsSm/Ld7wkf3Gu5uDJr/ds/+G0UMQJ0A6O0RhH09WnEKcHfL2P8pwCrbiyS9uZd17wP8AfAG4GuSft89Httoew4wB6C9vX3kP9Ixtjl97Nc7zNNA/dHh7kXsSOoMAa0AxrVMjwVW9tH2DFqGf4BjgVMlPUE1dHSCpGtblnuDK/8ObAT2G0DfIyJiEOoEwELgcEmHSdqFaid/U89GkvYCjgfmdpfZvsT2WNuHlvm+a/usUv0t4IQy7xHALkDuoImI2Eb6HQKyvV7SecDtVJeBXm17iaQZpb77rpfTgXm2n6257quBqyUtBl4Azu45/BMREVuPRtI+t7293V1dXcPdjRhhJO045wB2gO2IbU/SItvtPctzJ3BEREMlACIiGioBEBHRUAmAiIiGSgBERDRUAiAioqESABERDZUAiIhoqARARERDJQAiIhoqARAR0VAJgIiIhkoAREQ0VAIgIqKh6rwSMmLEk3p7s+nIss8++wx3F2IHkwCIHd62eIZ+ntUfI1GGgCIiGioBEBHRUAmAiIiGSgBERDRUAiAioqESABERDZUAiIhoqARARERDJQAiIhoqARAR0VC1AkDSZEmPSFom6eJe6i+UdH/5WSxpg6R9W+rbJN0n6eZe5r1AkiXtN7hNiYiIgeg3ACS1AVcAJwFHAlMlHdnaxvYs2xNtTwQuAe6yvaalyfnA0l6WPQ54K/DTLd6CiIjYInWOAI4Bltl+3PYLwPXAaZtpPxXo7J6QNBY4Gbiyl7afBS4C8hStiIhtrE4AHAwsb5leUcpeQtJuwGTgmy3Fl1Ht5Df2aHsq8KTtBza3cknTJXVJ6lq9enWN7kZERB11AqC3B6n39Y19CnB39/CPpFOAVbYXbbLAKig6gI/0t3Lbc2y3224fM2ZMje5GREQddQJgBTCuZXossLKPtmfQMvwDHAucKukJqqGjEyRdC7wKOAx4oNSNBe6V9MoB9T4iIrZYnQBYCBwu6TBJu1Dt5G/q2UjSXsDxwNzuMtuX2B5r+9Ay33dtn2X7Idv72z601K0Ajrb9s8FvUkRE1NHvG8Fsr5d0HnA70AZcbXuJpBmlfnZpejowz/azW623ERExZDSSXmPX3t7urq6u4e5GxEvklZCxPZO0yHZ7z/LcCRwR0VAJgIiIhkoAREQ0VAIgIqKhEgAREQ2VAIiIaKgEQEREQyUAIiIaKgEQEdFQCYCIiIZKAERENFQCICKioRIAERENlQCIiGioBEBEREMlACIiGioBEBHRUAmAiIiGSgBERDRUAiAioqESABERDZUAiIhoqARARERDJQAiIhpqp+HuQMT2SNI2mcf2gOeJGCoJgIheZMccTZAhoIiIhqoVAJImS3pE0jJJF/dSf6Gk+8vPYkkbJO3bUt8m6T5JN7eUzZL0sKQHJd0oae8h2aKIiKil3wCQ1AZcAZwEHAlMlXRkaxvbs2xPtD0RuAS4y/aalibnA0t7LPoOYILto4BHy3wREbGN1DkCOAZYZvtx2y8A1wOnbab9VKCze0LSWOBk4MrWRrbn2V5fJu8Bxg6k4xERMTh1AuBgYHnL9IpS9hKSdgMmA99sKb4MuAjYuJl1vBv4Th/LnC6pS1LX6tWra3Q3IiLqqBMAvV3b1tclElOAu7uHfySdAqyyvajPhUsdwHrgut7qbc+x3W67fcyYMTW6GxERddS5DHQFMK5leiywso+2Z9Ay/AMcC5wq6e3AKGBPSdfaPgtA0tnAKcBbnOvuIiK2qTpHAAuBwyUdJmkXqp38TT0bSdoLOB6Y211m+xLbY20fWub7bsvOfzLwYeBU288NeksiImJA+j0CsL1e0nnA7UAbcLXtJZJmlPrZpenpwDzbz9Zc9xeAlwN3lDso77E9Y3MzLFq06GlJP6m5/IhtaT/g6eHuREQffq+3QmXkJWLwJHXZbh/ufkQMRO4EjohoqARARERDJQAihsac4e5AxEDlHEBEREPlCCAioqESABERDZUAiK1K0gfKM6K2ZN5zJH1hEOv+kqS/2NL5W5Zz6+YeV95zG2u0/6ikJ8vj038saepg+zhUJB0k6RvD3Y/YNhIAsbV9ANiiANhe2H677V9upskHaNnGGu0BPlsen34a8EVJOw+ym0ga9Bv+bK+0PejQjJEhARBDQtLukm6R9EB5KdA7Jb0fOAiYL2l+afcv5emuSyR9rGX+N0j6QZn/3yWN7rH8kyX9UNJ+g+znKEn/W9JD5SVFk0r5bpK+Vl5Q9FVJP5LUXuqekLTfALbxie5+SnpXWeYDkr7csz+2HwOeA/Yp7S+UtLDM0/r5/E15gdIdkjolXVDKvyfp7yXdBZwv6fWS7pK0SNLtkg4s7d5fjjYelHR9KTu+5UVO90kaLelQSYv7+azOkXSDpNskPSbpHwfz3ySGT94JHENlMrDS9slQPRvK9q8k/TUwyXb3YxI6bK9R9aKhOyUdBTwMfBV4p+2FkvYEfte9YEmnA38NvN32M4Ps5/sAbL9O0muAeZKOAP4KeMb2UZImAPcPYhu7+/1aoAM41vbTanlLXkubo4HHbK+SdCJwONU7OATcJOmPqQLiz4H/RvVv9l6g9Qm7e9s+vhxF3AWcZnu1pHcCl1I9bv1i4DDbz7cMT10AvM/23ZL2ANbW/KwAJpb+PA88Iuly28uJESUBEEPlIeDTkj4F3Gz73/po9w5J06n+3zuQ6i1zBp6yvRDA9q8BVD0jahLQDpzYXT5IxwGXl/U8rOrZUkeU8s+V8sWSHhzENnY7AfhGdzD0eEveByW9F/h9qmABOLH83Fem96AKhNHAXNu/A5D07R7r+Wr5/WpgAv/5fK024KlS9yBwnaRvAd8qZXcDn5F0HXCD7RVlvm59fVYAd9r+VenPj6meNZMAGGEyBBRDwvajwOupdpL/IOkjPdtIOozqW+dbyqtAb6F6TLjo+x0Tj1PtAI/orbIMc9wv6cre6nubZYDlL6qzjb0ss6/t+qztVwPvBP6PpO7P4R+6X69q+7/YvqpG37ofwChgScv8r7N9Yqk7merVrq8HFknayfYngfcAuwL3lG/5Pfvfl+db/t5AvkyOSAmAGBKSDgKes30t8Gng6FL1G6odOMCeVDurX0k6gOo901ANAR0k6Q1lWaP1nyc0fwL8GdVO8rU912v7bWVn956aXf0+cGZZzxHAIcAjwALgHaX8SOB1W7iNre6kOuJ5RZn/JUNAtm8AuoCzqZ64++4yHIOkgyXtX/o2pYzJ70G1M+/NI8AYSW8q8+8s6bWSXgaMsz2f6u18ewN7SHqV7Ydsf6r0oWcA9PVZxQ4iqR1D5XXALEkbgXXAuaV8DvAdSU/ZniTpPmAJ1Tf7uwFsv1DGqy+XtCvV+P+fdC/Y9iOSzgS+LmmK7f8YQL++KOmy8vdyqiGl2ZIeonoT3TllXPyfgWvK0M99VEMmv9qSbWzp9xJJlwJ3SdpQlntOL338OPAVYHz5+WEZivktcFY5L3IT8ABVIHb10rfuz/EvgM+rej/HTlSvZH0UuLaUiero45eS/q6c2N0A/JjqtawHtizyn/v4rHrZhBiJ8iiICKCclN7Z9lpJr6L69n6E7ReGuWsASNrD9m9V3W/wfWC67XuHu18xsuUIIKKyG9WlnDtTfUs+d3vZ+RdzytDUKOCa7PxjKOQIICKioXISOCKioRIAERENlQCIiGioBEBEREMlACIiGur/A3nqjmZi/rbVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stack_model = LogisticRegression(solver='sag', C=1.6213309780417264, max_iter=1800, random_state=10)\n",
    "\n",
    "# get meta df\n",
    "models_stack = copy.deepcopy(models)\n",
    "models_stack.pop(1)\n",
    "df_meta_train = get_stack_df(models_stack, X_train, X_train_km, y_train)\n",
    "\n",
    "# cross val scores from stacking\n",
    "results = list()\n",
    "name = [model['name'] +'_' for model in models_stack]\n",
    "scores = evaluate_model(stack_model, df_meta_train, y_train)\n",
    "score = np.mean(scores)\n",
    "results.append(scores)\n",
    "print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "\n",
    "# plot stack model performance for comparison\n",
    "plt.boxplot(results, labels=['stack - ' + stack_model.__class__.__name__], showmeans=True)\n",
    "plt.title('Stacking Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 100 iterations\n",
      "Starting hold out prediction with 5 splits for CalibratedClassifierCV.\n",
      "          0\n",
      "0  0.231152\n",
      "1  0.695096\n",
      "2  0.567928\n",
      "3  0.722188\n",
      "4  0.643830\n",
      "Starting hold out prediction with 5 splits for LGBMClassifier.\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "          0\n",
      "0  0.260928\n",
      "1  0.698825\n",
      "2  0.456899\n",
      "3  0.741388\n",
      "4  0.609898\n",
      "Starting hold out prediction with 5 splits for GaussianNB.\n",
      "              0\n",
      "0  5.501525e-10\n",
      "1  9.953064e-01\n",
      "2  3.057126e-02\n",
      "3  9.999980e-01\n",
      "4  1.000000e+00\n",
      ">['lsvc_', 'lgbm_', 'bayes_'] 0.746 (0.002)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stack_model = LogisticRegression(solver='sag', C=1.6213309780417264, max_iter=1800, random_state=10)\n",
    "\n",
    "# get meta df\n",
    "models_stack = copy.deepcopy(models)\n",
    "models_stack.pop(0)\n",
    "df_meta_train = get_stack_df(models_stack, X_train, X_train_km, y_train)\n",
    "\n",
    "# cross val scores from stacking\n",
    "results = list()\n",
    "name = [model['name'] +'_' for model in models_stack]\n",
    "scores = evaluate_model(stack_model, df_meta_train, y_train)\n",
    "score = np.mean(scores)\n",
    "results.append(scores)\n",
    "print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "\n",
    "# plot stack model performance for comparison\n",
    "plt.boxplot(results, labels=['stack - ' + stack_model.__class__.__name__], showmeans=True)\n",
    "plt.title('Stacking Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 17:50:54,746]\u001b[0m A new study created in memory with name: Logistic regression\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:51:01,172]\u001b[0m Trial 0 finished with value: 0.7509228749607932 and parameters: {'solver': 'newton-cg', 'C': 1.813027073372824, 'max_iter': 2100}. Best is trial 0 with value: 0.7509228749607932.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:51:13,585]\u001b[0m Trial 1 finished with value: 0.7509228727379683 and parameters: {'solver': 'newton-cg', 'C': 1.1142658974823565, 'max_iter': 9500}. Best is trial 0 with value: 0.7509228749607932.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:51:19,358]\u001b[0m Trial 2 finished with value: 0.7509228710708497 and parameters: {'solver': 'newton-cg', 'C': 1.5274034347604613, 'max_iter': 2500}. Best is trial 0 with value: 0.7509228749607932.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:51:31,087]\u001b[0m Trial 3 finished with value: 0.750922869403731 and parameters: {'solver': 'sag', 'C': 1.6578618707484019, 'max_iter': 1800}. Best is trial 0 with value: 0.7509228749607932.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:51:33,818]\u001b[0m Trial 4 finished with value: 0.7509228844077993 and parameters: {'solver': 'liblinear', 'C': 0.6253330686085112, 'max_iter': 2700}. Best is trial 4 with value: 0.7509228844077993.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:51:36,572]\u001b[0m Trial 5 finished with value: 0.750922877183618 and parameters: {'solver': 'liblinear', 'C': 0.30640398175530076, 'max_iter': 1000}. Best is trial 4 with value: 0.7509228844077993.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:51:41,722]\u001b[0m Trial 6 finished with value: 0.7509228741272339 and parameters: {'solver': 'newton-cg', 'C': 1.3660000391827718, 'max_iter': 1100}. Best is trial 4 with value: 0.7509228844077993.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:51:53,603]\u001b[0m Trial 7 finished with value: 0.7509229627623785 and parameters: {'solver': 'sag', 'C': 0.6325366353172103, 'max_iter': 1500}. Best is trial 7 with value: 0.7509229627623785.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:51:59,129]\u001b[0m Trial 8 finished with value: 0.7509228730158215 and parameters: {'solver': 'newton-cg', 'C': 1.6920880044052435, 'max_iter': 4400}. Best is trial 7 with value: 0.7509229627623785.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:52:04,973]\u001b[0m Trial 9 finished with value: 0.7509228741272339 and parameters: {'solver': 'newton-cg', 'C': 1.0970625722715621, 'max_iter': 5300}. Best is trial 7 with value: 0.7509229627623785.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:52:05,879]\u001b[0m Trial 10 finished with value: 0.7509228749607932 and parameters: {'solver': 'lbfgs', 'C': 0.6105484048028186, 'max_iter': 6300}. Best is trial 7 with value: 0.7509229627623785.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:52:11,957]\u001b[0m Trial 11 finished with value: 0.750922871904409 and parameters: {'solver': 'newton-cg', 'C': 0.6267477016184336, 'max_iter': 3900}. Best is trial 7 with value: 0.7509229627623785.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:52:18,322]\u001b[0m Trial 12 finished with value: 0.7509230074967306 and parameters: {'solver': 'newton-cg', 'C': 0.023672809391721117, 'max_iter': 200}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:52:29,753]\u001b[0m Trial 13 finished with value: 0.7509229385891574 and parameters: {'solver': 'saga', 'C': 0.06398442364866924, 'max_iter': 200}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:52:43,363]\u001b[0m Trial 14 finished with value: 0.7509228538439563 and parameters: {'solver': 'sag', 'C': 0.024884056643301733, 'max_iter': 100}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:52:49,165]\u001b[0m Trial 15 finished with value: 0.7509228635688154 and parameters: {'solver': 'newton-cg', 'C': 0.33264552779332146, 'max_iter': 7200}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:52:55,123]\u001b[0m Trial 16 finished with value: 0.7509228785728838 and parameters: {'solver': 'newton-cg', 'C': 0.8808224555715167, 'max_iter': 3600}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:53:01,027]\u001b[0m Trial 17 finished with value: 0.7509228549553688 and parameters: {'solver': 'newton-cg', 'C': 0.3126328420583524, 'max_iter': 8900}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:53:16,525]\u001b[0m Trial 18 finished with value: 0.7509228794064432 and parameters: {'solver': 'newton-cg', 'C': 0.8958813633010143, 'max_iter': 3300}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:53:22,252]\u001b[0m Trial 19 finished with value: 0.7509228757943527 and parameters: {'solver': 'newton-cg', 'C': 0.4435253109368435, 'max_iter': 1000}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:53:27,857]\u001b[0m Trial 20 finished with value: 0.7509228752386463 and parameters: {'solver': 'newton-cg', 'C': 1.9835657001234535, 'max_iter': 5300}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:53:39,037]\u001b[0m Trial 21 finished with value: 0.750922843841244 and parameters: {'solver': 'saga', 'C': 0.07326186281502878, 'max_iter': 400}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:53:50,248]\u001b[0m Trial 22 finished with value: 0.750922867458759 and parameters: {'solver': 'newton-cg', 'C': 0.167847345912498, 'max_iter': 1300}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 17:54:01,459]\u001b[0m Trial 23 finished with value: 0.7509228471754814 and parameters: {'solver': 'saga', 'C': 0.19998684312060375, 'max_iter': 100}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:54:07,065]\u001b[0m Trial 24 finished with value: 0.7509228741272339 and parameters: {'solver': 'newton-cg', 'C': 0.510662456428667, 'max_iter': 1500}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:54:12,767]\u001b[0m Trial 25 finished with value: 0.7509228777393244 and parameters: {'solver': 'newton-cg', 'C': 0.7853331498681584, 'max_iter': 2900}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:54:22,605]\u001b[0m Trial 26 finished with value: 0.7509228744050871 and parameters: {'solver': 'newton-cg', 'C': 0.1612274198440602, 'max_iter': 500}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:54:33,234]\u001b[0m Trial 27 finished with value: 0.7509228816292681 and parameters: {'solver': 'saga', 'C': 0.44901553485783274, 'max_iter': 2100}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:54:39,060]\u001b[0m Trial 28 finished with value: 0.7509229477583101 and parameters: {'solver': 'newton-cg', 'C': 0.031459038967654014, 'max_iter': 800}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:54:44,642]\u001b[0m Trial 29 finished with value: 0.7509228724601152 and parameters: {'solver': 'newton-cg', 'C': 1.2960501761948802, 'max_iter': 2000}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:54:59,957]\u001b[0m Trial 30 finished with value: 0.7509228774614713 and parameters: {'solver': 'newton-cg', 'C': 0.8036304212553508, 'max_iter': 7400}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:55:06,362]\u001b[0m Trial 31 finished with value: 0.750922923862942 and parameters: {'solver': 'newton-cg', 'C': 0.053856753100571156, 'max_iter': 800}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:55:31,435]\u001b[0m Trial 32 finished with value: 0.750922864680228 and parameters: {'solver': 'newton-cg', 'C': 0.2514344834566028, 'max_iter': 100}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:55:38,299]\u001b[0m Trial 33 finished with value: 0.7509229852684811 and parameters: {'solver': 'newton-cg', 'C': 0.01912805268215094, 'max_iter': 1700}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:55:44,868]\u001b[0m Trial 34 finished with value: 0.7509228699594371 and parameters: {'solver': 'newton-cg', 'C': 0.4040076398796691, 'max_iter': 2400}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:55:51,101]\u001b[0m Trial 35 finished with value: 0.7509228677366122 and parameters: {'solver': 'newton-cg', 'C': 0.2063998298937068, 'max_iter': 1800}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:55:57,325]\u001b[0m Trial 36 finished with value: 0.7509228746829402 and parameters: {'solver': 'newton-cg', 'C': 0.5575887699365046, 'max_iter': 3100}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:56:22,973]\u001b[0m Trial 37 finished with value: 0.7509228752386463 and parameters: {'solver': 'newton-cg', 'C': 0.15048133628221838, 'max_iter': 1500}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 17:56:39,502]\u001b[0m Trial 38 finished with value: 0.7509228844077993 and parameters: {'solver': 'sag', 'C': 0.3568025374336733, 'max_iter': 2400}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\kaggle-pgnov21\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "\u001b[32m[I 2021-11-28 17:56:52,889]\u001b[0m Trial 39 finished with value: 0.7509228719044089 and parameters: {'solver': 'newton-cg', 'C': 1.2400353291244308, 'max_iter': 4500}. Best is trial 12 with value: 0.7509230074967306.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 40\n",
      "Best trial: {'solver': 'newton-cg', 'C': 0.023672809391721117, 'max_iter': 200}\n",
      "Best score: 0.7509230074967306\n"
     ]
    }
   ],
   "source": [
    "# optimize logistic regression\n",
    "study = optuna.create_study(direction='maximize', study_name=\"Logistic regression\")\n",
    "func = lambda trial: objective_logreg(trial, X_train, y_train,  X_val, y_val)\n",
    "study.optimize(func, n_trials=40)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print('Best score:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='newton-cg', C=0.023672809391721117, max_iter=200)\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict_proba(df_test)[:,1]\n",
    "\n",
    "output = pd.DataFrame({'id': ids, 'target': preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 18:21:40,476]\u001b[0m A new study created in memory with name: LinearSVC\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:21:51,970]\u001b[0m Trial 0 finished with value: 0.7497149200256543 and parameters: {'C': 0.6965933474301265, 'max_iter': 9000}. Best is trial 0 with value: 0.7497149200256543.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:22:03,594]\u001b[0m Trial 1 finished with value: 0.7497149208590719 and parameters: {'C': 1.547469698675367, 'max_iter': 6000}. Best is trial 1 with value: 0.7497149208590719.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:22:16,235]\u001b[0m Trial 2 finished with value: 0.7497149194700427 and parameters: {'C': 0.8836134159726222, 'max_iter': 1000}. Best is trial 1 with value: 0.7497149208590719.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:22:32,521]\u001b[0m Trial 3 finished with value: 0.7497149169697902 and parameters: {'C': 0.3900984305648511, 'max_iter': 9000}. Best is trial 1 with value: 0.7497149208590719.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:22:48,255]\u001b[0m Trial 4 finished with value: 0.7497149194700425 and parameters: {'C': 1.8374541010699128, 'max_iter': 9000}. Best is trial 1 with value: 0.7497149208590719.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:23:03,226]\u001b[0m Trial 5 finished with value: 0.7497149200256543 and parameters: {'C': 1.8992594111583148, 'max_iter': 8000}. Best is trial 1 with value: 0.7497149208590719.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:23:18,358]\u001b[0m Trial 6 finished with value: 0.7497149205812661 and parameters: {'C': 1.447856962300075, 'max_iter': 5000}. Best is trial 1 with value: 0.7497149208590719.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:23:34,215]\u001b[0m Trial 7 finished with value: 0.7497149200256543 and parameters: {'C': 1.6316376028146569, 'max_iter': 7000}. Best is trial 1 with value: 0.7497149208590719.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:23:49,789]\u001b[0m Trial 8 finished with value: 0.7497149208590719 and parameters: {'C': 1.5402190575248818, 'max_iter': 9000}. Best is trial 1 with value: 0.7497149208590719.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:24:05,553]\u001b[0m Trial 9 finished with value: 0.7497149264151886 and parameters: {'C': 0.03680059416542098, 'max_iter': 6000}. Best is trial 9 with value: 0.7497149264151886.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:24:20,839]\u001b[0m Trial 10 finished with value: 0.749714915580761 and parameters: {'C': 0.11266994760520341, 'max_iter': 3000}. Best is trial 9 with value: 0.7497149264151886.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:24:36,779]\u001b[0m Trial 11 finished with value: 0.749714920581266 and parameters: {'C': 1.1422116793824248, 'max_iter': 5000}. Best is trial 9 with value: 0.7497149264151886.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:24:53,713]\u001b[0m Trial 12 finished with value: 0.7497149600296948 and parameters: {'C': 0.012249147757314706, 'max_iter': 6000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:25:10,135]\u001b[0m Trial 13 finished with value: 0.749714917247596 and parameters: {'C': 0.08185725182393516, 'max_iter': 4000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:25:26,443]\u001b[0m Trial 14 finished with value: 0.7497149175254018 and parameters: {'C': 0.4304378687721492, 'max_iter': 7000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:25:43,035]\u001b[0m Trial 15 finished with value: 0.749714917247596 and parameters: {'C': 0.3878922941761538, 'max_iter': 3000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:26:00,208]\u001b[0m Trial 16 finished with value: 0.7497149114136734 and parameters: {'C': 0.05969122767447917, 'max_iter': 6000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:26:17,444]\u001b[0m Trial 17 finished with value: 0.7497149197478485 and parameters: {'C': 0.7044722465788231, 'max_iter': 7000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:26:35,426]\u001b[0m Trial 18 finished with value: 0.7497149144695375 and parameters: {'C': 0.2898128975246978, 'max_iter': 4000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:26:53,356]\u001b[0m Trial 19 finished with value: 0.7497149211368777 and parameters: {'C': 1.1736116472088023, 'max_iter': 1000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:27:10,055]\u001b[0m Trial 20 finished with value: 0.7497149186366251 and parameters: {'C': 0.6177590163630956, 'max_iter': 10000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:27:26,795]\u001b[0m Trial 21 finished with value: 0.7497149208590719 and parameters: {'C': 1.185496439462121, 'max_iter': 1000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:27:43,551]\u001b[0m Trial 22 finished with value: 0.7497149197478485 and parameters: {'C': 0.9666190091740713, 'max_iter': 2000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:28:03,203]\u001b[0m Trial 23 finished with value: 0.7497149205812661 and parameters: {'C': 1.3621346689446379, 'max_iter': 4000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:28:19,007]\u001b[0m Trial 24 finished with value: 0.7497149208590719 and parameters: {'C': 1.18832952245995, 'max_iter': 6000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:28:36,811]\u001b[0m Trial 25 finished with value: 0.7497149133583143 and parameters: {'C': 0.19708948472005894, 'max_iter': 5000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:28:54,834]\u001b[0m Trial 26 finished with value: 0.7497149180810135 and parameters: {'C': 0.5379506440776661, 'max_iter': 3000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:29:12,532]\u001b[0m Trial 27 finished with value: 0.7497149200256543 and parameters: {'C': 0.8460577892451493, 'max_iter': 8000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:29:28,273]\u001b[0m Trial 28 finished with value: 0.7497149128027025 and parameters: {'C': 0.2859674848766892, 'max_iter': 2000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:29:42,427]\u001b[0m Trial 29 finished with value: 0.7497149569738306 and parameters: {'C': 0.01333097735883924, 'max_iter': 8000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:29:56,331]\u001b[0m Trial 30 finished with value: 0.74971495836286 and parameters: {'C': 0.013386361991219679, 'max_iter': 8000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:30:10,576]\u001b[0m Trial 31 finished with value: 0.7497149286376353 and parameters: {'C': 0.026192396241509992, 'max_iter': 8000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:30:25,002]\u001b[0m Trial 32 finished with value: 0.7497149147473434 and parameters: {'C': 0.2294896900174097, 'max_iter': 8000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:30:38,891]\u001b[0m Trial 33 finished with value: 0.7497149272486061 and parameters: {'C': 0.0333364808838066, 'max_iter': 10000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:30:52,967]\u001b[0m Trial 34 finished with value: 0.7497149136361201 and parameters: {'C': 0.16632842647051643, 'max_iter': 8000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:31:06,646]\u001b[0m Trial 35 finished with value: 0.7497149180810134 and parameters: {'C': 0.44841863595128667, 'max_iter': 7000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:31:20,446]\u001b[0m Trial 36 finished with value: 0.7497149133583142 and parameters: {'C': 0.28118294374865493, 'max_iter': 9000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:31:34,292]\u001b[0m Trial 37 finished with value: 0.7497149586406656 and parameters: {'C': 0.015724266088701023, 'max_iter': 8000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:31:48,045]\u001b[0m Trial 38 finished with value: 0.7497149153029551 and parameters: {'C': 0.15519566917935476, 'max_iter': 10000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 18:32:02,012]\u001b[0m Trial 39 finished with value: 0.7497149166919842 and parameters: {'C': 0.331935711754267, 'max_iter': 7000}. Best is trial 12 with value: 0.7497149600296948.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 40\n",
      "Best trial: {'C': 0.012249147757314706, 'max_iter': 6000}\n",
      "Best score: 0.7497149600296948\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize', study_name=\"LinearSVC\")\n",
    "func = lambda trial: objective_linearSVC(trial, X_train, y_train,  X_val, y_val)\n",
    "study.optimize(func, n_trials=40)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print('Best score:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7490073647154942\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(dual=False, C=0.012249147757314706, max_iter=10000)\n",
    "clf = CalibratedClassifierCV(base_estimator=model, cv=5)\n",
    "scores = evaluate_model(model, X, y)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "improvement = [\n",
    "                {'col': 'f93', 'score': 0.74937980496359},\n",
    "                {'col': 'f51', 'score': 0.74929966989194},\n",
    "                {'col': 'f87', 'score': 0.749286577319145},\n",
    "                {'col': 'f68', 'score': 0.749277139834924},\n",
    "                {'col': 'f78', 'score': 0.749276882213393},\n",
    "                {'col': 'f62', 'score': 0.749275147148718},\n",
    "                {'col': 'f89', 'score': 0.749274390959197},\n",
    "                {'col': 'f52', 'score': 0.749274337874286},\n",
    "                {'col': 'f56', 'score': 0.749272925899996},\n",
    "                {'col': 'f99', 'score': 0.749269564354892},\n",
    "                {'col': 'f94', 'score': 0.749269362702158},\n",
    "                {'col': 'f61', 'score': 0.749268842818711},\n",
    "                {'col': 'f69', 'score': 0.74926548927119},\n",
    "                {'col': 'f88', 'score': 0.749265103672684},\n",
    "                {'col': 'f58', 'score': 0.749264578471603},\n",
    "                {'col': 'f71', 'score': 0.749263915691012},\n",
    "                {'col': 'f92', 'score': 0.749263337182983},\n",
    "                {'col': 'f83', 'score': 0.749263137845553},\n",
    "                {'col': 'f73', 'score': 0.749262998472393},\n",
    "                {'col': 'f79', 'score': 0.749262939316809},\n",
    "                {'col': 'f53', 'score': 0.749262568712333},\n",
    "                {'col': 'f85', 'score': 0.749262562170475},\n",
    "                {'col': 'f74', 'score': 0.749262225483844},\n",
    "                {'col': 'f77', 'score': 0.749261144172846},\n",
    "                {'col': 'f97', 'score': 0.749260238700895},\n",
    "                {'col': 'f59', 'score': 0.749260187189176},\n",
    "                {'col': 'f70', 'score': 0.749260078084847},\n",
    "                {'col': 'f60', 'score': 0.749259985882995},\n",
    "                {'col': 'f72', 'score': 0.749259923139526},\n",
    "                {'col': 'f63', 'score': 0.749259705338838},\n",
    "                {'col': 'f84', 'score': 0.749259697064632},\n",
    "                {'col': 'f66', 'score': 0.749259548369621},\n",
    "                {'col': 'f91', 'score': 0.749259409284883},\n",
    "                {'col': 'f65', 'score': 0.749259081163499},\n",
    "                {'col': 'f48', 'score': 0.749258667148775},\n",
    "                {'col': 'f49', 'score': 0.749258585306697},\n",
    "                {'col': 'f47', 'score': 0.749258369703664},\n",
    "                {'col': 'f90', 'score': 0.749258194850275},\n",
    "                {'col': 'f54', 'score': 0.749257967613653},\n",
    "                {'col': 'f76', 'score': 0.749257919343268},\n",
    "                {'col': 'f80', 'score': 0.74925790348247},\n",
    "                {'col': 'f86', 'score': 0.749257678676559},\n",
    "                {'col': 'f64', 'score': 0.74925764556949},\n",
    "                {'col': 'f81', 'score': 0.749257545496114},\n",
    "                {'col': 'f67', 'score': 0.749257539881676},\n",
    "                {'col': 'f55', 'score': 0.749257196943374},\n",
    "                {'col': 'f50', 'score': 0.749256959290237},\n",
    "                {'col': 'f98', 'score': 0.749256646449602},\n",
    "                {'col': 'f95', 'score': 0.749256167263361},\n",
    "                {'col': 'f82', 'score': 0.749255080858109},\n",
    "                {'col': 'f75', 'score': 0.749254809977639},\n",
    "                {'col': 'f96', 'score': 0.749254111891067},\n",
    "                {'col': 'f57', 'score': 0.749253100324584},\n",
    "                {'col': 'f20', 'score': 0.749065261635948},\n",
    "                {'col': 'f9', 'score': 0.749024452041971},\n",
    "                {'col': 'f16', 'score': 0.749022277167482},\n",
    "                {'col': 'f44', 'score': 0.749019719653472},\n",
    "                {'col': 'f24', 'score': 0.749017390532322},\n",
    "              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# baseline_score = 0.7490073647154942\n",
    "# improved_cols = []\n",
    "# for col in X.columns:\n",
    "#         print(col)\n",
    "#         model = LinearSVC(dual=False, C=0.012249147757314706, max_iter=10000)\n",
    "#         clf = CalibratedClassifierCV(base_estimator=model, cv=5)\n",
    "\n",
    "#         X_new = copy.deepcopy(X_train)\n",
    "#         new_col = col + '_bin'\n",
    "#         X_new[new_col], bins = pd.qcut(X_train[col], q=1000, retbins=True, labels=False)\n",
    "\n",
    "#         scores = evaluate_model(model, X_new, y_train)\n",
    "#         new_score = scores.mean()\n",
    "#         if new_score >= baseline_score + 0.00001:\n",
    "#             new_col = {'col': col, 'score': new_score}\n",
    "#             improved_cols.append(new_col)\n",
    "# print(improved_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_new = copy.deepcopy(df_test)\n",
    "# X_new.drop(['f1'], axis=1, inplace=True)\n",
    "# df_test_new['f2_bin'] = pd.cut(df_test_new['f2'], bins=bins, labels=False, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(dual=False, C=0.012249147757314706, max_iter=10000)\n",
    "clf = CalibratedClassifierCV(base_estimator=model, cv=5)\n",
    "\n",
    "\n",
    "X_new = copy.deepcopy(X_train)\n",
    "df_test_new = copy.deepcopy(df_test)\n",
    "\n",
    "col = 'f51'\n",
    "new_col = col + '_bin'\n",
    "X_new[new_col], bins = pd.qcut(X_new[col], q=1000, retbins=True, labels=False)\n",
    "df_test_new[new_col] = pd.cut(df_test_new[col], bins=bins, labels=False, include_lowest=True)\n",
    "df_test_new[new_col].fillna(df_test_new[new_col].mode()[0], inplace=True)\n",
    "\n",
    "col = 'f52'\n",
    "new_col = col + '_bin'\n",
    "X_new[new_col], bins = pd.qcut(X_new[col], q=1000, retbins=True, labels=False)\n",
    "df_test_new[new_col] = pd.cut(df_test_new[col], bins=bins, labels=False, include_lowest=True)\n",
    "df_test_new[new_col].fillna(df_test_new[new_col].mode()[0], inplace=True)\n",
    "\n",
    "clf.fit(X_new, y_train)\n",
    "\n",
    "preds = clf.predict_proba(df_test_new)[:,1]\n",
    "\n",
    "output = pd.DataFrame({'id': ids, 'target': preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_stack(models_in, stack_model_in, X_in, y_in, features, df_test_in, ids_in):\n",
    "    \"\"\"Generate predictions for a single model\"\"\"\n",
    "    \n",
    "    X_in = X_in[features]\n",
    "    df_test_in = df_test_in[features]\n",
    "    \n",
    "    meta_test_in = []\n",
    "    for model in models_in:\n",
    "        # Fit model\n",
    "\n",
    "        # Create hold out predictions for a classifier\n",
    "        if model.__class__.__name__ == 'LinearSVC':\n",
    "            clf = CalibratedClassifierCV(base_estimator=model, cv=n_splits)\n",
    "        else:\n",
    "            clf = model\n",
    "        \n",
    "        clf.fit(X_in, y_in)\n",
    "        meta_test_model = clf.predict_proba(df_test_in)\n",
    "    \n",
    "        # Remove redundant column - 0th column = 1-first column in a two class dataset \n",
    "        meta_test_model = np.delete(meta_test_model, 0, axis=1).ravel()\n",
    "    \n",
    "        # Gather meta training data\n",
    "        meta_test_in.append(meta_test_model)\n",
    "    \n",
    "        meta_test_in = np.array(meta_test_in).T \n",
    "        df_meta_test_in = pd.DataFrame(meta_test_in)\n",
    "\n",
    "    # Optional (Add original features to meta)\n",
    "    df_meta_test_in = pd.DataFrame(np.concatenate((df_meta_test_in, df_test_in), axis=1))\n",
    "    \n",
    "    stack_model_in.fit(pd.DataFrame(df_meta_train), y_train_norm)\n",
    "\n",
    "    # Final output\n",
    "    preds = stack_model.predict_proba(df_meta_test)[:,1]\n",
    "    output = pd.DataFrame({'id': ids, 'target': preds})\n",
    "    output.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    preds = clf.predict_proba(df_test_in)[:,1]\n",
    "    df_preds = pd.DataFrame({'id': ids_in, 'target': preds})\n",
    "    return df_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optimize-models\"></a>\n",
    "## Optimize models\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lightgbm(trial):\n",
    "    \"\"\"Optimize logistic regression model using optuna\"\"\"\n",
    "    \n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 11, 101, step=10)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 10, step=1)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 2.0)\n",
    "    \n",
    "    model = LGBMClassifier(num_leaves=num_leaves\n",
    "                           , max_depth=max_depth\n",
    "                           , learning_rate=learning_rate\n",
    "                           , objective='binary'\n",
    "                           , random_state=5)\n",
    "    model.fit(X_train_norm, y_train_norm)\n",
    "    preds = model.predict_proba(X_val_norm)[:,1]\n",
    "    score = roc_auc_score(y_val_norm, preds)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 22:45:21,858]\u001b[0m A new study created in memory with name: LightGBM\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:45:33,351]\u001b[0m Trial 0 finished with value: 0.729726569958354 and parameters: {'num_leaves': 81, 'max_depth': 5, 'learning_rate': 0.4139371668653664}. Best is trial 0 with value: 0.729726569958354.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:45:50,222]\u001b[0m Trial 1 finished with value: 0.7350786127919944 and parameters: {'num_leaves': 31, 'max_depth': 9, 'learning_rate': 0.23455617314768773}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:45:58,082]\u001b[0m Trial 2 finished with value: 0.7241467739241488 and parameters: {'num_leaves': 101, 'max_depth': 2, 'learning_rate': 1.145256335798105}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:46:05,701]\u001b[0m Trial 3 finished with value: 0.7307384510239672 and parameters: {'num_leaves': 61, 'max_depth': 2, 'learning_rate': 0.5457435485692936}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:46:20,366]\u001b[0m Trial 4 finished with value: 0.651507903528062 and parameters: {'num_leaves': 31, 'max_depth': 7, 'learning_rate': 1.8733064134781878}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:46:28,783]\u001b[0m Trial 5 finished with value: 0.7229611065666455 and parameters: {'num_leaves': 21, 'max_depth': 3, 'learning_rate': 1.116907323119684}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:46:38,502]\u001b[0m Trial 6 finished with value: 0.711177057930091 and parameters: {'num_leaves': 71, 'max_depth': 4, 'learning_rate': 1.2086546013819819}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:46:57,037]\u001b[0m Trial 7 finished with value: 0.7323456143899234 and parameters: {'num_leaves': 81, 'max_depth': 7, 'learning_rate': 0.17828767619482358}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:47:07,102]\u001b[0m Trial 8 finished with value: 0.723460319501907 and parameters: {'num_leaves': 91, 'max_depth': 4, 'learning_rate': 0.6717424777040208}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:47:21,556]\u001b[0m Trial 9 finished with value: 0.7180658602860154 and parameters: {'num_leaves': 11, 'max_depth': 7, 'learning_rate': 0.08228763941127352}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:47:38,368]\u001b[0m Trial 10 finished with value: 0.6594304436892962 and parameters: {'num_leaves': 41, 'max_depth': 10, 'learning_rate': 1.6403661982451097}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:47:59,355]\u001b[0m Trial 11 finished with value: 0.7301013324096601 and parameters: {'num_leaves': 51, 'max_depth': 9, 'learning_rate': 0.08955345172335916}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:48:15,027]\u001b[0m Trial 12 finished with value: 0.72677606622879 and parameters: {'num_leaves': 61, 'max_depth': 8, 'learning_rate': 0.3316801049998142}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:48:27,656]\u001b[0m Trial 13 finished with value: 0.7030744993544169 and parameters: {'num_leaves': 41, 'max_depth': 10, 'learning_rate': 0.7734330335988168}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:48:48,730]\u001b[0m Trial 14 finished with value: 0.716931101977208 and parameters: {'num_leaves': 71, 'max_depth': 6, 'learning_rate': 0.048654353723161514}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:48:59,293]\u001b[0m Trial 15 finished with value: 0.7231263888018612 and parameters: {'num_leaves': 11, 'max_depth': 8, 'learning_rate': 0.8534467539999204}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:49:17,274]\u001b[0m Trial 16 finished with value: 0.7247621952619762 and parameters: {'num_leaves': 101, 'max_depth': 8, 'learning_rate': 0.31144158008539324}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:49:32,946]\u001b[0m Trial 17 finished with value: 0.7325448281196394 and parameters: {'num_leaves': 31, 'max_depth': 6, 'learning_rate': 0.2690904557593553}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:49:45,032]\u001b[0m Trial 18 finished with value: 0.6795966671519822 and parameters: {'num_leaves': 31, 'max_depth': 6, 'learning_rate': 1.4101715398271395}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:49:55,474]\u001b[0m Trial 19 finished with value: 0.7236335126684172 and parameters: {'num_leaves': 31, 'max_depth': 5, 'learning_rate': 0.5447672360163431}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:50:05,992]\u001b[0m Trial 20 finished with value: 0.7143785389831109 and parameters: {'num_leaves': 21, 'max_depth': 9, 'learning_rate': 0.8477634906148083}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:50:21,023]\u001b[0m Trial 21 finished with value: 0.7334689899698384 and parameters: {'num_leaves': 51, 'max_depth': 7, 'learning_rate': 0.22578556021566012}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:50:40,677]\u001b[0m Trial 22 finished with value: 0.7326354951820816 and parameters: {'num_leaves': 51, 'max_depth': 9, 'learning_rate': 0.2697161168411229}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:50:55,671]\u001b[0m Trial 23 finished with value: 0.7186900934945314 and parameters: {'num_leaves': 51, 'max_depth': 9, 'learning_rate': 0.4701075272146816}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:51:08,848]\u001b[0m Trial 24 finished with value: 0.7128698180393762 and parameters: {'num_leaves': 41, 'max_depth': 10, 'learning_rate': 0.6364263845823717}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:51:27,578]\u001b[0m Trial 25 finished with value: 0.7344108477921403 and parameters: {'num_leaves': 51, 'max_depth': 9, 'learning_rate': 0.2282060570196645}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:51:52,325]\u001b[0m Trial 26 finished with value: 0.7006099069942205 and parameters: {'num_leaves': 61, 'max_depth': 7, 'learning_rate': 0.022925785733345777}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:52:13,204]\u001b[0m Trial 27 finished with value: 0.7350020173861028 and parameters: {'num_leaves': 41, 'max_depth': 8, 'learning_rate': 0.20143781181807865}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:52:25,013]\u001b[0m Trial 28 finished with value: 0.7080544500511072 and parameters: {'num_leaves': 21, 'max_depth': 8, 'learning_rate': 0.9616798146070997}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:52:40,295]\u001b[0m Trial 29 finished with value: 0.725700904658082 and parameters: {'num_leaves': 41, 'max_depth': 9, 'learning_rate': 0.4279036254865061}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:52:57,329]\u001b[0m Trial 30 finished with value: 0.7201799855550162 and parameters: {'num_leaves': 71, 'max_depth': 8, 'learning_rate': 0.4113154410771154}. Best is trial 1 with value: 0.7350786127919944.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:53:18,398]\u001b[0m Trial 31 finished with value: 0.735336246732417 and parameters: {'num_leaves': 51, 'max_depth': 10, 'learning_rate': 0.19045551737738176}. Best is trial 31 with value: 0.735336246732417.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:53:36,138]\u001b[0m Trial 32 finished with value: 0.735608734921519 and parameters: {'num_leaves': 41, 'max_depth': 10, 'learning_rate': 0.16009554199052495}. Best is trial 32 with value: 0.735608734921519.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:53:53,444]\u001b[0m Trial 33 finished with value: 0.7355741772421915 and parameters: {'num_leaves': 41, 'max_depth': 10, 'learning_rate': 0.19012540605966122}. Best is trial 32 with value: 0.735608734921519.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:54:06,643]\u001b[0m Trial 34 finished with value: 0.7194129819280983 and parameters: {'num_leaves': 31, 'max_depth': 10, 'learning_rate': 0.5656840916855166}. Best is trial 32 with value: 0.735608734921519.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:54:19,522]\u001b[0m Trial 35 finished with value: 0.7315230161627145 and parameters: {'num_leaves': 21, 'max_depth': 10, 'learning_rate': 0.40842752272958827}. Best is trial 32 with value: 0.735608734921519.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 22:54:41,697]\u001b[0m Trial 36 finished with value: 0.733680391801035 and parameters: {'num_leaves': 41, 'max_depth': 10, 'learning_rate': 0.13298928601825408}. Best is trial 32 with value: 0.735608734921519.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:55:00,029]\u001b[0m Trial 37 finished with value: 0.7268634823529679 and parameters: {'num_leaves': 61, 'max_depth': 10, 'learning_rate': 0.3423141619908766}. Best is trial 32 with value: 0.735608734921519.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:55:20,553]\u001b[0m Trial 38 finished with value: 0.6994875015285098 and parameters: {'num_leaves': 31, 'max_depth': 9, 'learning_rate': 0.026611370494423248}. Best is trial 32 with value: 0.735608734921519.\u001b[0m\n",
      "\u001b[32m[I 2021-11-15 22:55:37,097]\u001b[0m Trial 39 finished with value: 0.7256643000711207 and parameters: {'num_leaves': 21, 'max_depth': 10, 'learning_rate': 0.5245903234797886}. Best is trial 32 with value: 0.735608734921519.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 40\n",
      "Best trial: {'num_leaves': 41, 'max_depth': 10, 'learning_rate': 0.16009554199052495}\n",
      "Best score: 0.735608734921519\n",
      "Wall time: 10min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name=\"LightGBM\")\n",
    "func = lambda trial: objective_lightgbm(trial)\n",
    "study.optimize(func, n_trials=40)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print('Best score:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'n_estimators': 200, 'max_features': 'log2', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'solver': 'sag', 'C': 1.6213309780417264, 'ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'num_leaves': 41, 'max_depth': 10, 'learning_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                                             params\n",
       "0  RandomForestClassifier  {'n_estimators': 200, 'max_features': 'log2', ...\n",
       "0      LogisticRegression  {'solver': 'sag', 'C': 1.6213309780417264, 'ma...\n",
       "0          LGBMClassifier  {'num_leaves': 41, 'max_depth': 10, 'learning_..."
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.DataFrame([['LGBMClassifier', study.best_trial.params]])\n",
    "df_new.columns = ['model', 'params']\n",
    "df_model_params_optimized = pd.concat([df_model_params_optimized, df_new], axis=0)\n",
    "df_model_params_optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"stacking-manual\"></a>\n",
    "## Stacking - Manual\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T19:01:37.453276Z",
     "iopub.status.busy": "2021-11-12T19:01:37.452991Z",
     "iopub.status.idle": "2021-11-12T19:01:37.469443Z",
     "shell.execute_reply": "2021-11-12T19:01:37.468575Z",
     "shell.execute_reply.started": "2021-11-12T19:01:37.453247Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create hold out predictions (meta-features)\n",
    "def generate_meta_features(model, X_in, y_in, cv):\n",
    "    \"\"\"Generate meta features for base classifier model, to be used later for stacking\n",
    "\n",
    "    Keyword arguments:\n",
    "    model -- model to evaluate\n",
    "    X_in -- dataframe with features minus target\n",
    "    y_in -- target series\n",
    "    cv -- cross-validation iterator \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"Performing cross validation hold out predictions for stacking\"\"\"\n",
    "    # Initilize\n",
    "    n_classes = len(np.unique(y_in)) # Assuming that training data contains all classes\n",
    "    meta_features = np.zeros((X_in.shape[0], n_classes)) \n",
    "    n_splits = cv.get_n_splits(X_in, y_in)\n",
    "    \n",
    "    # Loop over folds\n",
    "    print(\"Starting hold out prediction with {} splits for {}.\".format(n_splits, model.__class__.__name__))\n",
    "    for train_idx, hold_out_idx in cv.split(X_in, y_in): \n",
    "        \n",
    "        # Split data\n",
    "        X_in_train = X_in.iloc[train_idx]    \n",
    "        y_in_train = y_in.iloc[train_idx]\n",
    "        X_in_hold_out = X_in.iloc[hold_out_idx]\n",
    "\n",
    "        # Fit estimator to K-1 parts and predict on hold out part\n",
    "        est = copy.deepcopy(model)\n",
    "        est.fit(X_in_train, y_in_train)\n",
    "        y_in_hold_out_pred = est.predict_proba(X_in_hold_out)\n",
    "        \n",
    "        # Fill in meta features\n",
    "        meta_features[hold_out_idx] = y_in_hold_out_pred\n",
    "\n",
    "    return meta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T19:01:48.037984Z",
     "iopub.status.busy": "2021-11-12T19:01:48.037269Z",
     "iopub.status.idle": "2021-11-12T19:02:03.314502Z",
     "shell.execute_reply": "2021-11-12T19:02:03.313662Z",
     "shell.execute_reply.started": "2021-11-12T19:01:48.037922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# # Predict on stacking classifier\n",
    "\n",
    "# # Set seed\n",
    "# if 'random_state' in stack_model.get_params().keys():\n",
    "#     stack_model.set_params(random_state=5)\n",
    "\n",
    "\n",
    "# scores = cross_val_score(estimator=stack_model, X=df_meta_train, y=y_train_norm, cv=n_splits, scoring='roc_auc')\n",
    "# score = scores.mean()\n",
    "# print('%.2f' % (score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"final\"></a>\n",
    "## Final submission\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(C=0.18747740329972518, max_iter=9000, dual=False, random_state=5)\n",
    "output = make_prediction_model(model, X_train_norm, y_train_norm, original_features, df_test_norm, ids)\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T19:02:03.316989Z",
     "iopub.status.busy": "2021-11-12T19:02:03.316388Z",
     "iopub.status.idle": "2021-11-12T19:02:07.901722Z",
     "shell.execute_reply": "2021-11-12T19:02:07.900801Z",
     "shell.execute_reply.started": "2021-11-12T19:02:03.316943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_norm = X_train_norm[original_features]\n",
    "meta_test = []\n",
    "for model in base_models:\n",
    "    # Fit model\n",
    "    \n",
    "    # Create hold out predictions for a classifier\n",
    "    if model.__class__.__name__ == 'LinearSVC':\n",
    "        clf = CalibratedClassifierCV(base_estimator=model, cv=n_splits)\n",
    "    else:\n",
    "        clf = model\n",
    "        \n",
    "    clf.fit(X_train_norm, y_train_norm)\n",
    "    meta_test_model = clf.predict_proba(df_test_norm)\n",
    "    \n",
    "    # Remove redundant column - 0th column = 1-first column in a two class dataset \n",
    "    meta_test_model = np.delete(meta_test_model, 0, axis=1).ravel()\n",
    "    \n",
    "    # Gather meta training data\n",
    "    meta_test.append(meta_test_model)\n",
    "    \n",
    "meta_test = np.array(meta_test).T \n",
    "df_meta_test = pd.DataFrame(meta_test)\n",
    "\n",
    "# Optional (Add original features to meta)\n",
    "df_meta_test = pd.DataFrame(np.concatenate((df_meta_test, df_test_norm), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T19:02:03.316989Z",
     "iopub.status.busy": "2021-11-12T19:02:03.316388Z",
     "iopub.status.idle": "2021-11-12T19:02:07.901722Z",
     "shell.execute_reply": "2021-11-12T19:02:07.900801Z",
     "shell.execute_reply.started": "2021-11-12T19:02:03.316943Z"
    }
   },
   "outputs": [],
   "source": [
    "stack_model.fit(pd.DataFrame(df_meta_train), y_train_norm)\n",
    "\n",
    "# Final output\n",
    "preds = stack_model.predict_proba(df_meta_test)[:,1]\n",
    "output = pd.DataFrame({'id': ids, 'target': preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
