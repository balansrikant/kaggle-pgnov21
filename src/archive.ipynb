{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e804b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_scores = []\n",
    "# for model in models_optimized:\n",
    "#     model_name = str(model.__class__.__name__)\n",
    "#     print('Evaluating model: ' + model_name)\n",
    "#     start = time.mktime(time.localtime())\n",
    "#     optimized_score = float(df_scores_optimized.loc[df_scores_optimized['model'] == model_name, 'cross_val_score'])\n",
    "\n",
    "#     cols = drop_features_return_scores(model, optimized_score, 0.05, X_train_norm, y_train_norm, n_splits, 'roc_auc')\n",
    "#     if len(cols) > 0:\n",
    "#         print(cols)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc36ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model_drop_features(\n",
    "#     model, \n",
    "#     X_in: pd.DataFrame, \n",
    "#     y_in: pd.Series,\n",
    "#     features: list,\n",
    "#     n: int) -> list:\n",
    "#     \"\"\"Return list of scores for a model by dropping features\n",
    "\n",
    "#     Arguments:\n",
    "#     :model - model to be evaluated\n",
    "#     :X_in - dataframe (train) minus target\n",
    "#     :y_in - series (target values for train)\n",
    "#     :features - list of features in asc order of correlation\n",
    "#     :n - number of features to drop \n",
    "    \n",
    "#     Returns:\n",
    "#     scores - list of scores for model\n",
    "#     \"\"\"\n",
    "    \n",
    "#     cols = features[n:]\n",
    "#     X_new = X_in[cols]\n",
    "#     cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "#     scores = cross_val_score(model, X_new, y_in, scoring='roc_auc', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    \n",
    "#     return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe59989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops = [10, 20, 30]\n",
    "# for drop in drops:\n",
    "#     # evaluate the models and store results\n",
    "#     results, names = list(), list()\n",
    "#     for model in models:\n",
    "#         name = model['name']\n",
    "#         scores = evaluate_model_drop_features(model['model'], \n",
    "#                                               X, \n",
    "#                                               y, \n",
    "#                                               list(featureScores['Specs']), \n",
    "#                                               drop\n",
    "#                                              )\n",
    "                                             \n",
    "#         key = 'drop_' + str(drop) + '_score'\n",
    "#         model[key] = np.mean(scores)\n",
    "#         results.append(scores)\n",
    "#         names.append(name)\n",
    "#         print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "\n",
    "#     # plot model performance for comparison\n",
    "#     plt.boxplot(results, labels=names, showmeans=True)\n",
    "#     plt.title(str(drop))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d9306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_distribution(X_in: pd.DataFrame, n_cols: int=5):\n",
    "#     \"\"\"Plot distribution of pandas dataframe columns\n",
    "\n",
    "#     Keyword arguments:\n",
    "#     X_in -- dataframe with features minus target\n",
    "#     n_cols -- number of subplots in a row (default 5) \n",
    "#     \"\"\"\n",
    "#     if len(X_in.columns) % n_cols == 0:\n",
    "#         n_rows = len(X_in.columns) // n_cols\n",
    "#     else:\n",
    "#         n_rows = (len(X_in.columns) // n_cols) + 1\n",
    "        \n",
    "#     fig, axs = plt.subplots(n_rows, n_cols, figsize=(30, 30))\n",
    "\n",
    "#     i = 0\n",
    "#     j = 0\n",
    "#     for col in original_features:\n",
    "#         axs[i,j].hist(list(X_in.loc[:, col]))\n",
    "#         axs[i,j].set_title(col, loc='right', y=0.9,  pad= -10)\n",
    "\n",
    "#         j += 1\n",
    "#         if j == n_cols:\n",
    "#             j = 0\n",
    "#             i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cdba593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate the models by adding kmeans label and store results\n",
    "# results, names = list(), list()\n",
    "# important_features = list(featureScores.sort_values(by='Abs_score', ascending=False).head(15)['Specs'])\n",
    "# X_temp = get_kmeans_labels(X, important_features, 10)\n",
    "# for model in models:\n",
    "#     name = model['name']\n",
    "#     scores = evaluate_model(model['model'], X_temp, y)\n",
    "#     model['kmeans_label_scores'] = np.mean(scores)\n",
    "#     results.append(scores)\n",
    "#     names.append(name)\n",
    "#     print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "    \n",
    "# # plot model performance for comparison\n",
    "# plt.boxplot(results, labels=names, showmeans=True)\n",
    "# plt.title('KMeans Label Scores')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f95037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.04 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# params={'n_estimators':[100,200,400,800,1600]\n",
    "#         , 'criterion':['gini','entropy']\n",
    "#         , 'max_depth': [2,3,4,5,6,7,8,9,10]\n",
    "#         , 'max_features': ['auto', 'sqrt', 'log2']\n",
    "#        }\n",
    "\n",
    "# model = RandomForestClassifier(random_state=5)\n",
    "# randomized_search = RandomizedSearchCV(model\n",
    "#                                        , param_distributions=params\n",
    "#                                        , n_iter=20\n",
    "#                                        , scoring = 'roc_auc'\n",
    "#                                        , n_jobs=-1\n",
    "#                                        , cv=n_splits\n",
    "#                                       )\n",
    "# randomized_search.fit(X_train_norm, y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8100b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_estimator = randomized_search.best_estimator_\n",
    "# best_score = randomized_search.best_score_\n",
    "# best_params = randomized_search.best_params_\n",
    "# print(best_params)\n",
    "# print(best_score)\n",
    "# print(best_estimator)\n",
    "\n",
    "# {'n_estimators': 200, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini'}\n",
    "# 0.7206188873635405\n",
    "# RandomForestClassifier(max_depth=10, max_features='log2', n_estimators=200, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056e0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.DataFrame([['RandomForestClassifier', \"{'n_estimators': 200, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini'}\"]])\n",
    "# df_new.columns = ['model', 'params']\n",
    "# df_model_params_optimized = pd.concat([df_model_params_optimized, df_new], axis=0)\n",
    "# df_model_params_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905d4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.DataFrame([['LogisticRegression', study.best_trial.params]])\n",
    "# df_new.columns = ['model', 'params']\n",
    "# df_model_params_optimized = pd.concat([df_model_params_optimized, df_new], axis=0)\n",
    "# df_model_params_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bfc9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_kmeans_dist_ratios(\n",
    "#     X_in: pd.DataFrame, \n",
    "#     features: list,\n",
    "#     n_clusters: int) -> list:\n",
    "#     \"\"\"Return kmeans labels for a dataframe\n",
    "\n",
    "#     Arguments:\n",
    "#     :X_in - dataframe (train) minus target\n",
    "#     :features - list of important features\n",
    "#     :n_clusters - number of kmeans clusters\n",
    "    \n",
    "#     Returns:\n",
    "#     X_temp - dataframe (train) minus target plus kmeans labels\n",
    "#     \"\"\"\n",
    "#     kmeans = KMeans(n_clusters=n_clusters, random_state=3)\n",
    "#     X_temp = copy.deepcopy(X_in)\n",
    "#     kmeans.fit(X_temp[features])\n",
    "\n",
    "#     cluster_cols = [f\"cluster{i+1}\" for i in range(n_clusters)]\n",
    "\n",
    "#     cluster_distances = kmeans.transform(X_temp[features])\n",
    "#     X_temp_cluster_distances = pd.DataFrame(cluster_distances, columns=cluster_cols, index=X_temp.index)\n",
    "\n",
    "#     new_cols = []\n",
    "#     for i in cluster_cols:\n",
    "#         for j in cluster_cols:\n",
    "#             if i != j:\n",
    "#                 new_col_name = i + '_' + j\n",
    "#                 X_temp_cluster_distances[new_col_name] = X_temp_cluster_distances[i] / X_temp_cluster_distances[j]\n",
    "#                 new_cols.append(new_col_name)\n",
    "            \n",
    "#     X_temp = X_temp.join(X_temp_cluster_distances[new_cols])\n",
    "    \n",
    "#     return X_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392412e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
